{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QjceqWg-C0F"
      },
      "source": [
        "<h5> Αρχικά εισάγεται η βιβλιοθήκη mowl και η torch\n",
        "και αρχικοποιείται η διαθέσιμη προς χρήση μνήμη για το Java Virtual Machine ως 10 Gigabytes.\n",
        "\n",
        "**Προσοχή: πριν να τρέξει ο κώδικας του github θα πρέπει να έχει εγκατασταθεί στο virtual environment το πακέτο της βιβλιοθήκης mOWL (!pip install mowl-borg). Αυτή η διαδικασία γίνεται \"χειροκίνητα\" από τον κάθε χρήστη που εκτελεί το collab.** </h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ENx3ENNf-jhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mowl-borg"
      ],
      "metadata": {
        "id": "8My_2PMm-D9a",
        "outputId": "28c6e915-6307-4548-e456-db1c416f14d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mowl-borg\n",
            "  Downloading mowl_borg-1.0.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (8.1.8)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (1.2.15)\n",
            "Requirement already satisfied: gensim>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (4.3.3)\n",
            "Collecting JPype1==1.5.0 (from mowl-borg)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (2.2.2)\n",
            "Collecting pykeen==1.11.0 (from mowl-borg)\n",
            "  Downloading pykeen-1.11.0-py3-none-any.whl.metadata (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (2.32.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (1.6.0)\n",
            "Requirement already satisfied: scipy<1.15.0 in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (1.13.1)\n",
            "Collecting temp (from mowl-borg)\n",
            "  Downloading temp-2020.7.2.tar.gz (1.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (2.5.1+cu121)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from mowl-borg) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1==1.5.0->mowl-borg) (24.2)\n",
            "Collecting dataclasses-json (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting click-default-group (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading click_default_group-1.2.4-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting optuna>=2.0.0 (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from pykeen==1.11.0->mowl-borg) (0.9.0)\n",
            "Collecting more-click (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from pykeen==1.11.0->mowl-borg) (10.5.0)\n",
            "Collecting pystow>=0.4.3 (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading pystow-0.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting docdata (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading docdata-0.0.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting class-resolver>=0.5.1 (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading class_resolver-0.5.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting torch-max-mem>=0.1.1 (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading torch_max_mem-0.1.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting torch-ppr>=0.0.7 (from pykeen==1.11.0->mowl-borg)\n",
            "  Downloading torch_ppr-0.0.8-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pykeen==1.11.0->mowl-borg) (4.12.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.3.0->mowl-borg) (7.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->mowl-borg) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mowl-borg) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->mowl-borg) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mowl-borg) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mowl-borg) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mowl-borg) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->mowl-borg) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->mowl-borg) (1.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->mowl-borg) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mowl-borg) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->mowl-borg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->mowl-borg) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->mowl-borg) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mowl-borg) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mowl-borg) (3.5.0)\n",
            "Collecting alembic>=1.5.0 (from optuna>=2.0.0->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna>=2.0.0->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna>=2.0.0->pykeen==1.11.0->mowl-borg) (2.0.36)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->mowl-borg) (1.17.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mowl-borg) (3.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna>=2.0.0->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen==1.11.0->mowl-borg) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen==1.11.0->mowl-borg)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading mowl_borg-1.0.1-py3-none-any.whl (68.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pykeen-1.11.0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.4/718.4 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading class_resolver-0.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystow-0.6.1-py3-none-any.whl (38 kB)\n",
            "Downloading torch_max_mem-0.1.3-py3-none-any.whl (10 kB)\n",
            "Downloading torch_ppr-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading click_default_group-1.2.4-py2.py3-none-any.whl (4.1 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading docdata-0.0.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
            "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: temp\n",
            "  Building wheel for temp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for temp: filename=temp-2020.7.2-py3-none-any.whl size=1230 sha256=5b89d30e24dc852d82516ee028237ac180879bb19a7f44bcf47d70b226cc89b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/f4/e0/661461cb3cbc2cd950cdd0ce8ba52bdc52a1122784a2f0e1dc\n",
            "Successfully built temp\n",
            "Installing collected packages: temp, mypy-extensions, more-click, marshmallow, Mako, JPype1, docdata, colorlog, click-default-group, class-resolver, typing-inspect, pystow, alembic, torch-max-mem, optuna, dataclasses-json, torch-ppr, pykeen, mowl-borg\n",
            "Successfully installed JPype1-1.5.0 Mako-1.3.8 alembic-1.14.0 class-resolver-0.5.4 click-default-group-1.2.4 colorlog-6.9.0 dataclasses-json-0.6.7 docdata-0.0.4 marshmallow-3.25.1 more-click-0.1.2 mowl-borg-1.0.1 mypy-extensions-1.0.0 optuna-4.1.0 pykeen-1.11.0 pystow-0.6.1 temp-2020.7.2 torch-max-mem-0.1.3 torch-ppr-0.0.8 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MpNa7bF9-C0H"
      },
      "outputs": [],
      "source": [
        "import mowl\n",
        "mowl.init_jvm(\"10g\")\n",
        "import torch as th"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFUjr8rN-C0H"
      },
      "source": [
        "<h3>Dataset που χρησημοποιήθηκε:</h3>\n",
        "Το dataset που χρησημοποιήθηκε είναι το PPIYeastDataset το οποίο είναι built-in στην mowl και οι σχέσεις μεταξύ πρωτεϊνών αναπαραστούνται σαν αξιώματα με τον παρακάτω τρόπο: <br>\n",
        "<b>protein1 ⊆ interacts_with.protein2</b> <br>\n",
        "Η επιλογή dataset επηρεάζει σημαντικά τον κώδικα καθώς αλλάζουν οι μέθοδοι για training και evaluation αναλόγως με την αρχιτεκτονική του dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nUtPx4-C0I"
      },
      "source": [
        "<h3>EL-Embedding μοντέλο</h3>\n",
        "Η EL γλώσσα απαρτίζεται απο τα παρακάτω GCIs:\n",
        "\n",
        "**GCI 0** -`C ⊑ D` <br>\n",
        "**GCI 1** -`C1 ⊓ C2 ⊑ D`<br>\n",
        "**GCI 2**-`C ⊑ ∃R.D` <br>\n",
        "**GCI 3**-`∃R.C ⊑ D` <br>\n",
        "**GCI bot 0**-`C ⊑ ⊥` <br>\n",
        "**GCI bot 1**-`C1 ⊓ C2 ⊑ ⊥` <br>\n",
        "**GCI bot 3**- `∃R.C ⊑ ⊥` <br>\n",
        "\n",
        "Στο EL module, η βασική λειτουργία είναι να οριστεί loss function για κάθε ένα από τα GCI.  Για τα PPI, υπάρχει έτοιμο model το ELEmPPI, αλλά σε διαφορετικά datasets, η επεξεργασία της κλάσης είναι αρκετά απλή. <br>(https://mowl.readthedocs.io/en/latest/_modules/mowl/models/elembeddings/examples/model_ppi.html#ELEmPPI) <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH4XK7nJ-C0I"
      },
      "source": [
        "## Εκπέδευη μοντέλου EL embedding\n",
        "Στις παραμέτρους του ELEmPPI μπορούν να δοκιμαστούν διάφορες τιμές για κάθε όρισμα"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eu2vtj9I-C0J",
        "outputId": "0a3789c0-2c14-4013-885a-954e95daa788"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:14<00:00,  1.34it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import logging\n",
        "from mowl.datasets.builtin import PPIYeastDataset\n",
        "from mowl.models import ELEmPPI\n",
        "\n",
        "# logging να αγνοεί τα info μηνύματα\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "\n",
        "# dataset που χρησιμοποιείται (το συγκεκριμένο είναι built-in)\n",
        "dataset = PPIYeastDataset()\n",
        "\n",
        "# initialize model with the required parameters\n",
        "model = ELEmPPI(dataset, #το dataset που χρησιμοποιείται για εκπέδευση (στο συγκεκριμένο μέσα στο ELemPPI παίρνει το training κομμ΄άτι του και τα GCIs αυτού\n",
        "                embed_dim=30, #διάσταση των embedding\n",
        "                learning_rate=0.001,#ρυθμός μάθησης (ρυθμός ενημέρωσης παραμέτρων εκπέδευσης σε κάθε βήμα)\n",
        "                epochs=100,#αριθμός εποχών (δλδ πλήρης επαναλήψεων εκπέδευσης)\n",
        "                batch_size=20000, #τα δείγματα που επεξεργάζονται σε κάθε βήμα\n",
        "                model_filepath=None,\n",
        "                device='cuda') #Χρήση cuda (gpu) για γρηγορότερους υπολογισμούς στο training\n",
        "\n",
        "#κλήση μεθόδου εκπέδευσης\n",
        "model.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T76qGqvF-C0L"
      },
      "source": [
        "## Evaluating\n",
        "\n",
        "To evaluation των embeddings διαφέρει ανάλογα με το dataset. Στο συγκεκριμένο παράδειγμα, χρησιμοποιείται το PPIYeastDataset και το built-in PPIEvaluator. <b> Κάθε κλάση Evaluator χαρακτηρίζεται από δύο κύρια σημεία: τον τύπο των οντοτήτων που εμπλέκονται και τον τύπο των αξιωμάτων που θα αξιολογηθούν. </b> Στην περίπτωση του PPIEvaluator, οι εμπλεκόμενες οντότητες είναι μόνο αυτές που εκπροσωπούν πρωτεΐνες, χωρίς να λαμβάνονται υπόψη άλλες οντότητες. Τα αξιώματα που αξιολογούνται με τον PPIEvaluator είναι του τύπου \"p1 αλληλεπιδρά με p2\" (εξού και το PPI όνομα). Κάθε dataset έχει τη δική του ιδιότητα evaluation_classes, όπου καθορίζει τι είδους οντότητες ή αξιώματα θα εξεταστούν από το dataset στο πλαίσιο της αξιολόγησης."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4HyamIoE-C0L"
      },
      "outputs": [],
      "source": [
        "from mowl.evaluation import PPIEvaluator\n",
        "model.set_evaluator(PPIEvaluator)\n",
        "model.evaluate(dataset.testing)\n",
        "\n",
        "data1 = model.metrics #αποθήκευση αποτελεσμάτων για το ELembedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s521pgkm-C0M"
      },
      "source": [
        "## ELBox Embedding\n",
        "Στην περίπτωση των EL Embeddings, τα γεωμετρικά αντικείμενα που αναπαριστούν τις κλάσεις της οντολογίας είναι μπάλες n-διαστάσεων. Ένα από τα GCI στην EL είναι: <br>\n",
        "`C1 ⊓ C2 ⊑ D'\n",
        "Όπως είναι φανερό, σε αυτό το GCI, υπάρχει μια πράξη τομής . Η υπολογιστική αυτή τομή χρησιμοποιώντας μπάλες δεν είναι μια κλειστή πράξη διότι η περιοχή που περιέχεται στην τομή δύο μπαλών δεν είναι μπάλα. Για να λυθεί αυτό το ζήτημα, γίνεται αλλαγή γεωμετρικών αντικειμένων σε κουτιά, για τα οποία η πράξη της τομής έχει την ιδιότητα της κλειστότητας.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "O-3OejFr-C0M",
        "outputId": "bfc24bcc-b941-444f-f513-896b12c16acd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:44<00:00,  2.24it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mowl.models.elboxembeddings.examples.model_ppi import ELBoxPPI\n",
        "model = ELBoxPPI(dataset,\n",
        "                 embed_dim=30,\n",
        "                 learning_rate=0.001,\n",
        "                 epochs=100,\n",
        "                 batch_size=20000,\n",
        "                 model_filepath=None,\n",
        "                 device='cuda')\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yGloQ-2-C0N"
      },
      "source": [
        "Εδώ χρησιμοποιείται για άλλη μια φορά το built-in evaluator για PPIs της mowl και αποθηκεύονται τα αποτελέσματα απόδοσης του embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjyf_DEh-C0N"
      },
      "outputs": [],
      "source": [
        "from mowl.evaluation import PPIEvaluator\n",
        "\n",
        "model.set_evaluator(PPIEvaluator)\n",
        "model.evaluate(dataset.testing)\n",
        "data2= model.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mf1bxav-C0N"
      },
      "source": [
        "## Embedding με χρήση γράφου\n",
        "<h3>TransE Embedding</h3>\n",
        "Στο παράδειγμα αυτό αρχικά προβάλλονται DL αξιώματα με του dataset σε γράφο με χρήση του DL2VecProjector και στην συνέχεια χρησιμοποιείται το μοντέλο TransE, όπου συνδυάζει τα διανύσματα των οντοτήτων με τις σχέσεις ως διανυσματικές μεταφράσεις, έτσι ώστε η αρχική οντότητα συν την σχέση να προσεγγίζει την τελική οντότητα (h + r ≈ t), για την παραγωγή των embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "s74TsZO8-C0N",
        "outputId": "432fca7a-83fe-4459-fbdb-5ef18564fb68",
        "colab": {
          "referenced_widgets": [
            "f3882db620484215a8b70fc42eccfa0f",
            "bc8e8d1228284cd2a23134d50f471fe7",
            "e73bc74c22e8449f9170e32c1aa9ff02",
            "9c6b170d858649ff91949de5d05f84c0",
            "dacd2030f95a464285a520ad0f56a47c",
            "86805248009d42ebbd2a608c9b1c2860",
            "d9cc4bd63ada4ca3b5b81d130eda151a",
            "d456e792b37b423e9084eb40b3ff4174",
            "0f5e3f0712cc42ef8aad94ec180a5bc6",
            "deb852e24218469289106bca0ea1ea92",
            "6395e3bf82884fa9a9d6777ab12f7ba8",
            "b3050dc10e50470ba11881a9d99d3730",
            "9fadc5b035a7495c91269260f39aee0e",
            "3b7ec3503bae4358b48edabbbfa673b3",
            "cffcd0f09d314d5581db13c3da39012a",
            "fafede34e79c461ca23459123fd1cbf0",
            "c6f143223e2e44a28a58ffe627be73f5",
            "fd857a00cd79485bb7d6d916d98b1f83",
            "1d564060573d43a8bb0917c347156551",
            "f24a37d0611e4c3685a5b63163e7e139",
            "147397423ffd4759afb681d86740fb6d"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There are 6840 classes not found in the graph. They might be ignored in the projection or they might be in the validation/testing set but not in the training set.\n",
            "WARNING:mowl.base_models.graph_model:There are 6840 classes not found in the graph. They might be ignored in the projection or they might be in the validation/testing set but not in the training set.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3882db620484215a8b70fc42eccfa0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training epochs on cuda:0:   0%|          | 0/20 [00:00<?, ?epoch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc8e8d1228284cd2a23134d50f471fe7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e73bc74c22e8449f9170e32c1aa9ff02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c6b170d858649ff91949de5d05f84c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dacd2030f95a464285a520ad0f56a47c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86805248009d42ebbd2a608c9b1c2860",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9cc4bd63ada4ca3b5b81d130eda151a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d456e792b37b423e9084eb40b3ff4174",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f5e3f0712cc42ef8aad94ec180a5bc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deb852e24218469289106bca0ea1ea92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6395e3bf82884fa9a9d6777ab12f7ba8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3050dc10e50470ba11881a9d99d3730",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fadc5b035a7495c91269260f39aee0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b7ec3503bae4358b48edabbbfa673b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cffcd0f09d314d5581db13c3da39012a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fafede34e79c461ca23459123fd1cbf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6f143223e2e44a28a58ffe627be73f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd857a00cd79485bb7d6d916d98b1f83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d564060573d43a8bb0917c347156551",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f24a37d0611e4c3685a5b63163e7e139",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "147397423ffd4759afb681d86740fb6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training batches on cuda:0:   0%|          | 0/10615 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mowl.models import GraphPlusPyKEENModel\n",
        "from mowl.projection import DL2VecProjector\n",
        "from pykeen.models import TransE\n",
        "\n",
        "model = GraphPlusPyKEENModel(dataset,device='cuda')\n",
        "model.set_projector(DL2VecProjector()) #προβολή του dataset σε γράφο\n",
        "model.set_kge_method(TransE, random_seed=42) #χρηση του transE για την παραγωγη embedding στον γράφο γνώσης\n",
        "model.optimizer = th.optim.Adam\n",
        "model.lr = 0.001\n",
        "model.batch_size = 32\n",
        "\n",
        "model.train(epochs = 20) #εκπέδευση μοντελου\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtutG3sn-C0N"
      },
      "source": [
        "Evaluation μοντέλου με χρήση του PPIEvaluator και αποθήκευση μετρικών απόδοσης."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCXVZ-cL-C0O",
        "outputId": "0944f2aa-f314-43a6-d328-f4516209504a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A custom EvaluationModel should be created depending on the task. This is a generic one.\n",
            "WARNING:mowl.models.graph_kge.graph_pykeen_model:A custom EvaluationModel should be created depending on the task. This is a generic one.\n"
          ]
        }
      ],
      "source": [
        "model.set_evaluator(PPIEvaluator)\n",
        "model.evaluate(dataset.testing)\n",
        "data3= model.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA92HaBX-C0O"
      },
      "source": [
        "### Συνακτικα μοντελα\n",
        "<h3> OPA2Vec </h3> <br>\n",
        "Για τα συνακτικά μοντέλα, απαραίτητη είναι η αναπαράσταση των αξιωμάτων σε μορφή text, ώστε στην συνέχεια με την χρήση ενός μοντέλου όπως το Word2Vec, να παραχθούν τα embedding. Στο συγκεκριμένο παράδειγμα, χρησιμοποιούνται και reasoners για να δημιουργηθούν και αξιώματα υποκλάσης, ισοδυναμίας και διάκρησης. Επιπλέον, χρησιμοποιείται άτυπη γνώση όπως μεταδεδομένα οντοτήτων (πχ συνώνημα, ορισμοί) με την χρήση του \"extract_and_save_annotation_corpus\" της mowl.corpus, όπου είναι και η διαφορά του μοντέλου από το Onto2Vec.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZqc7Vvr-C0O",
        "outputId": "925188fb-9f5c-48c0-a88b-fd4e8675c0d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:root:Number of inferred axioms: 555583.\n",
            "INFO:root:Number of inferred axioms: 56751.\n",
            "INFO:root:Generating axioms corpus\n",
            "INFO:root:Generating annotation corpus\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.025>', 'datetime': '2025-01-03T00:42:19.911182', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
            "INFO:root:Generating axioms corpus\n",
            "INFO:root:Generating annotation corpus\n",
            "INFO:mowl.base_models.syntactic_model:Corpus saved in opa2vec_corpus.txt\n",
            "INFO:gensim.models.word2vec:collecting all words and their counts\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 47899 words, keeping 14664 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 95373 words, keeping 24903 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 143517 words, keeping 33297 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 190563 words, keeping 40363 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 238610 words, keeping 46575 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 286842 words, keeping 52402 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 335234 words, keeping 57381 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 382560 words, keeping 61837 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 430662 words, keeping 65999 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 477756 words, keeping 69746 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 526612 words, keeping 73379 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 574092 words, keeping 76527 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 622096 words, keeping 79741 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 670377 words, keeping 82671 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 718661 words, keeping 85338 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 766393 words, keeping 87854 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 814525 words, keeping 90321 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 862874 words, keeping 92701 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 910637 words, keeping 94979 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 958211 words, keeping 96995 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 1006388 words, keeping 98986 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 1054012 words, keeping 100952 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 1101560 words, keeping 102827 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 1147853 words, keeping 104610 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 1195899 words, keeping 106340 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 1242908 words, keeping 108097 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 1289617 words, keeping 109741 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 1337207 words, keeping 111467 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 1385340 words, keeping 113159 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 1432246 words, keeping 114710 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 1478810 words, keeping 116253 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 1526707 words, keeping 117719 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 1573799 words, keeping 119242 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 1621342 words, keeping 120779 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #350000, processed 1668789 words, keeping 122283 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #360000, processed 1716133 words, keeping 123700 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #370000, processed 1762530 words, keeping 125138 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #380000, processed 1809475 words, keeping 126556 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #390000, processed 1856270 words, keeping 127868 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #400000, processed 1903075 words, keeping 129304 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #410000, processed 1950190 words, keeping 130739 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #420000, processed 1996321 words, keeping 132056 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #430000, processed 2042984 words, keeping 133379 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #440000, processed 2088985 words, keeping 134675 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #450000, processed 2138302 words, keeping 136028 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #460000, processed 2184087 words, keeping 137267 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #470000, processed 2232365 words, keeping 138648 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #480000, processed 2279470 words, keeping 139970 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #490000, processed 2326741 words, keeping 141297 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #500000, processed 2373917 words, keeping 142623 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #510000, processed 2421491 words, keeping 143918 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #520000, processed 2469056 words, keeping 145149 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #530000, processed 2516253 words, keeping 146352 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #540000, processed 2562751 words, keeping 147637 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #550000, processed 2610469 words, keeping 148932 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #560000, processed 2658043 words, keeping 150191 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #570000, processed 2705371 words, keeping 151476 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #580000, processed 2752065 words, keeping 152688 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #590000, processed 2799873 words, keeping 153911 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #600000, processed 2847410 words, keeping 155185 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #610000, processed 2894461 words, keeping 156382 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #620000, processed 2941088 words, keeping 157580 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #630000, processed 2988449 words, keeping 158838 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #640000, processed 3035475 words, keeping 159959 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #650000, processed 3083223 words, keeping 161208 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #660000, processed 3129892 words, keeping 162418 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #670000, processed 3176430 words, keeping 163606 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #680000, processed 3224099 words, keeping 164783 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #690000, processed 3271193 words, keeping 165925 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #700000, processed 3319171 words, keeping 167091 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #710000, processed 3366069 words, keeping 168235 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #720000, processed 3413308 words, keeping 169486 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #730000, processed 3461503 words, keeping 170638 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #740000, processed 3509045 words, keeping 171895 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #750000, processed 3556530 words, keeping 173076 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #760000, processed 3602517 words, keeping 174170 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #770000, processed 3649335 words, keeping 175279 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #780000, processed 3696915 words, keeping 176510 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #790000, processed 3744097 words, keeping 177644 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #800000, processed 3791279 words, keeping 178828 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #810000, processed 3839450 words, keeping 179973 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #820000, processed 3886085 words, keeping 181088 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #830000, processed 3934258 words, keeping 182290 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #840000, processed 3982464 words, keeping 183426 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #850000, processed 4030792 words, keeping 184636 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #860000, processed 4078690 words, keeping 185786 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #870000, processed 4125788 words, keeping 186897 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #880000, processed 4172929 words, keeping 188031 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #890000, processed 4220379 words, keeping 189171 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #900000, processed 4267346 words, keeping 190279 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #910000, processed 4313835 words, keeping 191405 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #920000, processed 4361546 words, keeping 192501 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #930000, processed 4409140 words, keeping 193634 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #940000, processed 4455229 words, keeping 194759 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #950000, processed 4502878 words, keeping 195892 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #960000, processed 4549750 words, keeping 197004 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #970000, processed 4598030 words, keeping 198180 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #980000, processed 4645798 words, keeping 199326 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #990000, processed 4692278 words, keeping 200419 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1000000, processed 4739313 words, keeping 201566 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1010000, processed 4786572 words, keeping 202605 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1020000, processed 4835181 words, keeping 203753 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1030000, processed 4881707 words, keeping 204786 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1040000, processed 4930036 words, keeping 205813 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1050000, processed 4977259 words, keeping 206848 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1060000, processed 5025300 words, keeping 207939 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1070000, processed 5073653 words, keeping 209034 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1080000, processed 5121346 words, keeping 210090 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1090000, processed 5168921 words, keeping 211108 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1100000, processed 5216364 words, keeping 212280 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1110000, processed 5263642 words, keeping 213382 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1120000, processed 5311702 words, keeping 214449 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1130000, processed 5357656 words, keeping 215468 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1140000, processed 5405606 words, keeping 216524 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1150000, processed 5452396 words, keeping 217581 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1160000, processed 5500669 words, keeping 218653 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1170000, processed 5547336 words, keeping 219717 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1180000, processed 5594888 words, keeping 220800 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1190000, processed 5642519 words, keeping 221880 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1200000, processed 5690209 words, keeping 223026 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1210000, processed 5737788 words, keeping 224023 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1220000, processed 5784962 words, keeping 225081 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1230000, processed 5831647 words, keeping 226107 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1240000, processed 5879349 words, keeping 227161 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1250000, processed 5926745 words, keeping 228192 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1260000, processed 5975199 words, keeping 229282 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1270000, processed 6023274 words, keeping 230320 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1280000, processed 6071088 words, keeping 231387 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1290000, processed 6119148 words, keeping 232415 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1300000, processed 6166013 words, keeping 233470 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1310000, processed 6214092 words, keeping 234527 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1320000, processed 6261706 words, keeping 235593 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1330000, processed 6308392 words, keeping 236663 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1340000, processed 6355080 words, keeping 237665 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1350000, processed 6402236 words, keeping 238722 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1360000, processed 6451930 words, keeping 240060 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1370000, processed 6532211 words, keeping 244549 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1380000, processed 6611932 words, keeping 247756 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1390000, processed 6674450 words, keeping 253706 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1400000, processed 6729238 words, keeping 261171 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1410000, processed 6790463 words, keeping 267342 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1420000, processed 6861023 words, keeping 271073 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1430000, processed 6934817 words, keeping 275402 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1440000, processed 6997168 words, keeping 280901 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1450000, processed 7073962 words, keeping 284847 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1460000, processed 7152944 words, keeping 289372 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1470000, processed 7222801 words, keeping 294332 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1480000, processed 7283587 words, keeping 300508 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1490000, processed 7355747 words, keeping 303828 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1500000, processed 7425051 words, keeping 307490 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1510000, processed 7494362 words, keeping 311073 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1520000, processed 7566559 words, keeping 314615 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1530000, processed 7633039 words, keeping 319467 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1540000, processed 7704473 words, keeping 324076 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1550000, processed 7773824 words, keeping 328389 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1560000, processed 7847897 words, keeping 332143 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1570000, processed 7919495 words, keeping 336355 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1580000, processed 7993805 words, keeping 340368 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1590000, processed 8063416 words, keeping 343003 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1600000, processed 8122217 words, keeping 349374 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1610000, processed 8184937 words, keeping 354716 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1620000, processed 8243926 words, keeping 361012 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1630000, processed 8320981 words, keeping 364002 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1640000, processed 8402163 words, keeping 367907 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1650000, processed 8479573 words, keeping 371420 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1660000, processed 8545239 words, keeping 376047 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1670000, processed 8613347 words, keeping 380192 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1680000, processed 8690514 words, keeping 383893 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1690000, processed 8774860 words, keeping 387662 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1700000, processed 8843794 words, keeping 391996 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1710000, processed 8914189 words, keeping 396495 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1720000, processed 8969462 words, keeping 402154 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1730000, processed 9034419 words, keeping 406866 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1740000, processed 9106125 words, keeping 408886 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1750000, processed 9164516 words, keeping 410961 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1760000, processed 9230763 words, keeping 413186 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1770000, processed 9296835 words, keeping 415534 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1780000, processed 9365621 words, keeping 417474 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1790000, processed 9431489 words, keeping 419317 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1800000, processed 9499945 words, keeping 421107 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1810000, processed 9569204 words, keeping 422993 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1820000, processed 9637306 words, keeping 424850 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1830000, processed 9709381 words, keeping 426664 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1840000, processed 9777101 words, keeping 431158 word types\n",
            "INFO:gensim.models.word2vec:PROGRESS: at sentence #1850000, processed 9840494 words, keeping 434406 word types\n",
            "INFO:gensim.models.word2vec:collected 435381 word types from a corpus of 9857089 raw words and 1852760 sentences\n",
            "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 435381 unique words (100.00% of original 435381, drops 0)', 'datetime': '2025-01-03T00:42:57.866813', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 9857089 word corpus (100.00% of original 9857089, drops 0)', 'datetime': '2025-01-03T00:42:57.867813', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 435381 items\n",
            "INFO:gensim.models.word2vec:sample=0.001 downsamples 38 most-common words\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 7682220.507176953 word corpus (77.9%% of prior 9857089)', 'datetime': '2025-01-03T00:42:59.783205', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'prepare_vocab'}\n",
            "INFO:gensim.models.word2vec:estimated required memory for 435381 words and 100 dimensions: 565995300 bytes\n",
            "INFO:gensim.models.word2vec:resetting layer weights\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-03T00:43:02.398031', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'build_vocab'}\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training model with 4 workers on 435381 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-03T00:43:02.399031', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 3.27% examples, 214821 words/s, in_qsize 1, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 14.22% examples, 467974 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 22.69% examples, 494891 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 33.54% examples, 547418 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 41.88% examples, 546737 words/s, in_qsize 1, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 52.24% examples, 568212 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 60.29% examples, 562466 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 70.73% examples, 577315 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 78.14% examples, 589960 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 87.36% examples, 629986 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0 - PROGRESS: at 96.80% examples, 665019 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 0: training on 9857089 raw words (7680784 effective words) took 11.6s, 661966 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 11.03% examples, 729352 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 19.81% examples, 647711 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 30.80% examples, 669036 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 39.02% examples, 634912 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 49.50% examples, 644083 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 57.57% examples, 624198 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 68.14% examples, 633354 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 75.99% examples, 631954 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 84.99% examples, 671894 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 94.50% examples, 706793 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 1: training on 9857089 raw words (7682099 effective words) took 10.8s, 708830 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 11.03% examples, 723774 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 19.46% examples, 636510 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 30.23% examples, 657179 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 38.45% examples, 626872 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 49.04% examples, 638251 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 56.21% examples, 609374 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 65.18% examples, 605143 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 72.90% examples, 578572 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 80.73% examples, 606174 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 87.79% examples, 620131 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 95.11% examples, 635609 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 2: training on 9857089 raw words (7682204 effective words) took 12.0s, 639818 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 4.28% examples, 279172 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 12.74% examples, 418352 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 18.78% examples, 405268 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 27.61% examples, 446300 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 36.63% examples, 474375 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 43.70% examples, 472015 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 53.14% examples, 492257 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 59.71% examples, 484587 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 69.48% examples, 501214 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 76.44% examples, 509672 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 84.03% examples, 539098 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 92.20% examples, 569389 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 3: training on 9857089 raw words (7681782 effective words) took 12.9s, 593354 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 7.44% examples, 491468 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 16.51% examples, 540761 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 22.81% examples, 496418 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 31.15% examples, 506946 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 39.13% examples, 508898 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 49.39% examples, 534727 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 57.45% examples, 532234 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 67.00% examples, 543767 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 76.60% examples, 568645 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 83.43% examples, 586391 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 91.36% examples, 612765 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 99.20% examples, 628339 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 4: training on 9857089 raw words (7682258 effective words) took 12.2s, 630827 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 6.99% examples, 459962 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 17.19% examples, 562908 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 24.52% examples, 532700 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 33.88% examples, 551602 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 40.73% examples, 531046 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 50.64% examples, 549383 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 58.70% examples, 545854 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 67.12% examples, 546089 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 75.13% examples, 553670 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 81.58% examples, 567433 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 88.95% examples, 588895 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 98.20% examples, 620565 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 5: training on 9857089 raw words (7682672 effective words) took 12.3s, 625948 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 7.21% examples, 474876 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 16.51% examples, 542860 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 23.74% examples, 518120 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 32.62% examples, 533295 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 40.73% examples, 532258 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 50.64% examples, 550953 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 58.70% examples, 546547 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 68.58% examples, 559101 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 78.21% examples, 590173 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 83.59% examples, 590150 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 90.50% examples, 605140 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 98.89% examples, 627863 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 6: training on 9857089 raw words (7682410 effective words) took 12.2s, 630758 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 8.22% examples, 539726 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 17.76% examples, 580403 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 23.74% examples, 503599 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 32.85% examples, 524786 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 41.99% examples, 518257 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 51.90% examples, 538781 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 59.82% examples, 535999 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 70.17% examples, 552835 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 79.37% examples, 586773 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 86.49% examples, 604058 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 95.90% examples, 640106 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 7: training on 9857089 raw words (7681743 effective words) took 11.8s, 653197 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 8.34% examples, 546861 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 18.21% examples, 597275 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 25.90% examples, 562360 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 35.48% examples, 575991 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 42.80% examples, 532432 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 50.64% examples, 529041 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 60.74% examples, 547486 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 68.70% examples, 543664 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 78.14% examples, 573786 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 85.14% examples, 593335 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 94.16% examples, 626687 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 8: training on 9857089 raw words (7682712 effective words) took 11.9s, 645186 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 8.11% examples, 533199 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 17.99% examples, 589561 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 25.56% examples, 554137 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 35.48% examples, 576981 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 43.36% examples, 560695 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 52.01% examples, 559493 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 59.27% examples, 547599 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 63.71% examples, 515225 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 71.07% examples, 510922 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 78.76% examples, 533931 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 84.33% examples, 540475 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 92.59% examples, 570799 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 9: training on 9857089 raw words (7682822 effective words) took 12.9s, 594998 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 7.44% examples, 484243 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 17.52% examples, 571776 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 24.99% examples, 536109 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 34.46% examples, 554608 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 43.02% examples, 543026 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 52.68% examples, 557670 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 61.89% examples, 546665 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 71.88% examples, 559675 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 80.21% examples, 590190 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 86.83% examples, 602090 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 95.11% examples, 627719 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 10: training on 9857089 raw words (7684196 effective words) took 12.0s, 641872 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 7.99% examples, 526871 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 17.87% examples, 587816 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 25.44% examples, 554523 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 35.03% examples, 570848 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 44.04% examples, 559239 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 53.26% examples, 565026 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 62.35% examples, 552861 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 71.76% examples, 560541 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 79.98% examples, 589047 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 85.66% examples, 592444 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 11 - PROGRESS: at 93.76% examples, 616993 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 11: training on 9857089 raw words (7681721 effective words) took 12.1s, 637001 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 8.78% examples, 461528 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 16.96% examples, 492624 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 25.21% examples, 505332 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 32.17% examples, 493626 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 42.11% examples, 522341 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 49.95% examples, 520501 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 59.15% examples, 531776 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 67.12% examples, 530328 words/s, in_qsize 1, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 76.95% examples, 559378 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 85.90% examples, 600477 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12 - PROGRESS: at 92.59% examples, 612029 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 12: training on 9857089 raw words (7683541 effective words) took 12.1s, 635361 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 8.67% examples, 573805 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 14.92% examples, 489770 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 23.16% examples, 504441 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 29.21% examples, 475371 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 38.68% examples, 503732 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 46.30% examples, 502062 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 55.77% examples, 518253 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 64.62% examples, 517610 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 74.18% examples, 534810 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 82.97% examples, 575171 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 89.74% examples, 589629 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13 - PROGRESS: at 99.05% examples, 621444 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 13: training on 9857089 raw words (7683265 effective words) took 12.3s, 624237 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 10.24% examples, 677527 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 17.41% examples, 571001 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 27.15% examples, 590003 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 34.22% examples, 557809 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 43.14% examples, 562358 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 50.87% examples, 552843 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 61.10% examples, 568995 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 68.92% examples, 561570 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 78.14% examples, 588877 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 86.97% examples, 625359 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14 - PROGRESS: at 93.67% examples, 635523 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 14: training on 9857089 raw words (7681745 effective words) took 11.7s, 656251 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 10.47% examples, 692732 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 18.66% examples, 613714 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 28.87% examples, 589452 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 39.13% examples, 607961 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 47.09% examples, 589453 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 57.34% examples, 601511 words/s, in_qsize 1, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 65.29% examples, 589758 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 75.13% examples, 607107 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 83.52% examples, 639135 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 90.35% examples, 649480 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15 - PROGRESS: at 99.70% examples, 678903 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 15: training on 9857089 raw words (7682314 effective words) took 11.3s, 679493 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 10.58% examples, 567128 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 20.74% examples, 607659 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 28.51% examples, 550183 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 38.00% examples, 565321 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 46.86% examples, 567958 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 53.60% examples, 547736 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 62.68% examples, 553944 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 70.17% examples, 546409 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 78.98% examples, 576325 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 87.66% examples, 609192 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16 - PROGRESS: at 94.16% examples, 618943 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 16: training on 9857089 raw words (7681996 effective words) took 12.0s, 637925 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 10.58% examples, 695566 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 18.78% examples, 615151 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 28.87% examples, 627327 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 34.22% examples, 557927 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 43.25% examples, 563734 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 49.61% examples, 539355 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 59.15% examples, 551356 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 66.78% examples, 536282 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 75.53% examples, 551080 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 84.25% examples, 590601 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 17 - PROGRESS: at 91.98% examples, 608250 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 17: training on 9857089 raw words (7681492 effective words) took 12.1s, 634420 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 10.58% examples, 698185 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 17.76% examples, 584147 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 26.47% examples, 575054 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 32.74% examples, 532762 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 41.31% examples, 537388 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 49.50% examples, 536258 words/s, in_qsize 1, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 55.30% examples, 512599 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 64.05% examples, 519365 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 71.76% examples, 517981 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 80.65% examples, 556156 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 89.59% examples, 593711 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18 - PROGRESS: at 95.90% examples, 599755 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 18: training on 9857089 raw words (7681505 effective words) took 12.5s, 613549 effective words/s\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 9.46% examples, 623646 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 17.41% examples, 568178 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 27.49% examples, 595873 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 34.69% examples, 564530 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 44.28% examples, 576735 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 51.33% examples, 556805 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 60.51% examples, 563288 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 68.81% examples, 556280 words/s, in_qsize 0, out_qsize 1\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 77.27% examples, 574491 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 84.77% examples, 599161 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 92.87% examples, 624097 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19 - PROGRESS: at 99.36% examples, 627535 words/s, in_qsize 0, out_qsize 0\n",
            "INFO:gensim.models.word2vec:EPOCH 19: training on 9857089 raw words (7682596 effective words) took 12.2s, 629644 effective words/s\n",
            "INFO:gensim.utils:Word2Vec lifecycle event {'msg': 'training on 197141780 raw words (153645857 effective words) took 241.0s, 637524 effective words/s', 'datetime': '2025-01-03T00:47:03.403489', 'gensim': '4.3.3', 'python': '3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'train'}\n"
          ]
        }
      ],
      "source": [
        "from mowl.corpus import extract_and_save_axiom_corpus, extract_and_save_annotation_corpus\n",
        "from mowl.owlapi import OWLAPIAdapter\n",
        "from mowl.reasoning import MOWLReasoner\n",
        "from org.semanticweb.elk.owlapi import ElkReasonerFactory\n",
        "from java.util import HashSet\n",
        "from mowl.models import SyntacticPlusW2VModel\n",
        "import os\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "reasoner_factory = ElkReasonerFactory()\n",
        "reasoner = reasoner_factory.createReasoner(dataset.ontology)\n",
        "mowl_reasoner = MOWLReasoner(reasoner)\n",
        "\n",
        "classes = dataset.ontology.getClassesInSignature()\n",
        "subclass_axioms = mowl_reasoner.infer_subclass_axioms(classes) #αξιωματα υποκλάσεων\n",
        "equivalent_class_axioms = mowl_reasoner.infer_equivalent_class_axioms(classes) #αξιωματα εξλισωσης κλάσεων\n",
        "\n",
        "adapter = OWLAPIAdapter()\n",
        "manager = adapter.owl_manager\n",
        "\n",
        "axioms = HashSet()\n",
        "axioms.addAll(subclass_axioms)\n",
        "axioms.addAll(equivalent_class_axioms)\n",
        "\n",
        "manager.addAxioms(dataset.ontology, axioms) #προσθηκη των αξιωματων που παρηχθηκαν απο το reasoner στην οντολογία που χρησιμοποιείται\n",
        "\n",
        "extract_and_save_axiom_corpus(dataset.ontology, \"opa2vec_corpus.txt\") #αποθηκευση ολων των αξιωματων που υπηρχαν και παράχθηκαν σε μορφη text\n",
        "extract_and_save_annotation_corpus(dataset.ontology, \"opa2vec_corpus.txt\", mode=\"a\") #επεκταση text με μεταδεδομένα όπως ορισμοί και περιγραφές στιγμιοτύπων\n",
        "\n",
        "\n",
        "model = SyntacticPlusW2VModel(dataset, corpus_filepath=\"opa2vec_corpus.txt\") #Word2Vec στο text για παραγωγη embedding\n",
        "model.set_w2v_model(min_count=1, workers=4, epochs=20)\n",
        "model.generate_corpus(save=True, with_annotations=True)\n",
        "model.train()\n",
        "os.remove(\"opa2vec_corpus.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w09kU0pk-C0O"
      },
      "source": [
        "### Evaluation του OPA2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWwOAJc2-C0O",
        "outputId": "04bd6d18-9c6b-4af6-8778-ccb6142112f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class http://4932.YCL020W not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YCL020W not found in w2v model\n",
            "Class http://4932.YCR108C not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YCR108C not found in w2v model\n",
            "Class http://4932.YDR182W-A not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YDR182W-A not found in w2v model\n",
            "Class http://4932.YDR504C not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YDR504C not found in w2v model\n",
            "Class http://4932.YGL176C not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YGL176C not found in w2v model\n",
            "Class http://4932.YHR078W not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YHR078W not found in w2v model\n",
            "Class http://4932.YJL195C not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YJL195C not found in w2v model\n",
            "Class http://4932.YLR444C not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YLR444C not found in w2v model\n",
            "Class http://4932.YML116W-A not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://4932.YML116W-A not found in w2v model\n",
            "Class http://www.w3.org/2002/07/owl#Nothing not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://www.w3.org/2002/07/owl#Nothing not found in w2v model\n",
            "Class http://www.w3.org/2002/07/owl#Thing not found in w2v model\n",
            "WARNING:mowl.models.syntactic.w2v_model:Class http://www.w3.org/2002/07/owl#Thing not found in w2v model\n"
          ]
        }
      ],
      "source": [
        "model.set_evaluator(PPIEvaluator)\n",
        "model.evaluate(dataset.testing)\n",
        "data4= model.metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RizkszBf-C0P"
      },
      "source": [
        "### Ευνοϊκή για σύγκριση αναπαράσταση αποδόσεων των μοντέλων με χρήση DataFrame της βιβλιοθήκης pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcoM8dQJ-C0P",
        "outputId": "0444c5da-f44e-4722-f0ba-564864d8213d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 mr      mrr        f_mr    f_mrr      auc    f_auc   hits@1  \\\n",
            "Model 1 1444.729900 0.004990 1444.729900 0.004990 0.760893 0.760893 0.000000   \n",
            "Model 2 1540.819103 0.004620 1540.819103 0.004620 0.744979 0.744979 0.000000   \n",
            "Model 3  400.716694 0.026006  400.716694 0.026006 0.933800 0.933800 0.000083   \n",
            "Model 4 1409.202658 0.004040 1409.202658 0.004040 0.766777 0.766777 0.000664   \n",
            "\n",
            "          hits@3  hits@10  hits@50  hits@100  f_hits@1  f_hits@3  f_hits@10  \\\n",
            "Model 1 0.001661 0.008056 0.035548  0.074668  0.000000  0.001661   0.008056   \n",
            "Model 2 0.001910 0.007309 0.036462  0.071346  0.000000  0.001910   0.007309   \n",
            "Model 3 0.014867 0.063040 0.244435  0.388538  0.000083  0.014867   0.063040   \n",
            "Model 4 0.002159 0.004900 0.023754  0.045100  0.000664  0.002159   0.004900   \n",
            "\n",
            "         f_hits@50  f_hits@100  \n",
            "Model 1   0.035548    0.074668  \n",
            "Model 2   0.036462    0.071346  \n",
            "Model 3   0.244435    0.388538  \n",
            "Model 4   0.023754    0.045100  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame([data1, data2, data3,data4], index=['Model 1', 'Model 2', 'Model 3', 'Model 4'])\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.6f}') #δεκαδική μορφή\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE31Txxt-C0P"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}